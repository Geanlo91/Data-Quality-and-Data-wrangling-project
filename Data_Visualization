import pandas as pd
import numpy as np
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re   

hdf5_file = "scraped_data.h5"
df = pd.DataFrame()


def sanitize_name(name):
    # Replace non-alphanumeric characters with underscores
    sanitized = re.sub(r'\W+', '_', name)
    # Ensure that the name doesn't start with a digit
    if sanitized[0].isdigit():
        sanitized = '_' + sanitized
    return sanitized
 
#define function which collects first row of each URL for each date
def aggregate_first_rows(hdf5_file, target_urls):
    # Sanitize the target URLs
    sanitized_urls = [sanitize_name(url) for url in target_urls]

    # Initialize dictionaries for aggregated data and column names
    aggregated_data = {url: [] for url in sanitized_urls}
    column_names = {url: None for url in sanitized_urls}

    with pd.HDFStore(hdf5_file, 'r') as store:
        for key in store.keys():
            # Remove the leading slash and sanitize the key
            sanitized_key = sanitize_name(key[1:])

            if sanitized_key in sanitized_urls:
                data = store[key]
                metadata = store.get_storer(key).attrs.metadata
                url = metadata.get('url', '')

                first_row = data.head(1)
                if column_names[sanitized_key] is None:
                    column_names[sanitized_key] = first_row.columns
                aggregated_data[sanitized_key].append(first_row)

    # Combine all first rows into separate DataFrames for each sanitized URL
    for sanitized_url in sanitized_urls:
        if aggregated_data[sanitized_url]:
            aggregated_data[sanitized_url] = pd.concat(aggregated_data[sanitized_url])[column_names[sanitized_url]]
        else:
            aggregated_data[sanitized_url] = pd.DataFrame(columns=column_names[sanitized_url])
        print(f"Aggregated data from {sanitized_url}")
        print(aggregated_data[sanitized_url])

    return aggregated_data

# Example usage
target_urls = ['https_za_investing_com_crypto_xrp_historical_data', 'https_www_skysports_com_la_liga_table', 'https_www_absa_co_za_indices_share_information_']
aggregated_tables = aggregate_first_rows(hdf5_file, target_urls)


def visualize_data(aggreggated_tables):
    for url, table in aggreggated_tables.items():
        if not table.empty:
            print(f"Visualizing data from {url}")
            plt.figure()
            table.plot()
            plt.title(url)
            plt.show()
        else:
            print(f"No data from {url}")
   
visualize_data(aggregated_tables)