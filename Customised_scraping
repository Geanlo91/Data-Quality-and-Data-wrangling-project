import pandas as pd
import requests
from bs4 import BeautifulSoup
import h5py
import datetime
import pandas as pd
import re

def is_numeric(df):
        # Check if the dataframe contains only numeric data
        for col in df.columns:
                try:
                  #attempt to convert the column to numeric
                
                  if not pd.to_numeric(df[col], errors='coerce').notnull().all():
                                return False
                except TypeError as e:
                        #Log the error and type of the problematic data
                        print(f"TypeError for column {col}: {e}")
                        print(f"Data type of column {col}: {type(df[col])}")
                        return False
        return True

def scrape_table(soup, start_column_name):
              print("starting to scrape tables")
              print("Looking for column:", start_column_name)
              
              # Find the table on the page using BeautifulSoup
              for table in soup.find_all('table'):
                                headers = [th.text.strip() for th in table.find_all('th')]
                            
                                if any (start_column_name in header for header in headers):
                                                  rows = table.find_all('tr')
                                                  data = []
                                                  for row in rows:
                                                                cols = row.find_all('td')
                                                                
                                                                cols = [ele.text.strip() for ele in cols]
                                                                if cols:
                                                                      data.append(cols)
                                                  df = pd.DataFrame(data, columns=headers)
                                                  

                                                  #Check if Data is predominantly numeric
                                                  if is_numeric(df):
                                                                   return df
                                                  else:
                                                                   print("Data is not predominantly numeric")
                                                                   return None
              print("Table with specified column not found")
                                            

              #Fallback to regex method if BeautifulSoup fails
              html_content = soup.prettify()
              matches = re.finditer(r'([a-zA-Z0-9\s]+)\s*:\s*(\d+)', html_content)
              numeric_data_with_headers = [(match.group(1), match.group(2)) for match in matches]
              if numeric_data_with_headers:
                                        return pd.DataFrame(numeric_data_with_headers, columns=['Key', 'Value'])
              print("No numeric data found with regex method")
              return None
#print all scraped data
def print_data(df):
          print("Printing scraped data")
          print(df)
          return

# Read CSV file
web_pages = pd.read_csv('web_pages.csv')

#Open the HDF5 file
with h5py.File('Scraped data_file.h5', 'a') as hf:
          for index, row in web_pages.iterrows():
                    url = row['url']
                    start_column = row['start_column_name']

                    response = requests.get(url)
                    if response.status_code == 200:
                              soup = BeautifulSoup(response.text, 'html.parser')
                              df = scrape_table(soup, start_column)
                              if df is not None and not df.empty:
                                sanitized_url = url.replace("https://", "").replace("/", "_").replace(":", "_").replace(".", "_")
                                dataset_name = f'{sanitized_url}_{datetime.datetime.now().strftime("%Y%m%d%H%M%S")}'
                                hf.create_dataset(dataset_name, data=df.to_numpy(), compression="gzip")
                                hf[dataset_name].attrs['Scraping_date'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                                #print the dataset including scraping date
                                print(f"Dataset: {dataset_name}\nData: {df}, \nScraped on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                  

                              else:
                                  print(f"No table found on the page {url}")
                                
                    else:
                        print(f"Page not found: {url}")
print("Scraping complete")
