import pandas as pd
import numpy as np
import requests 
import h5py
import matplotlib.pyplot as plt
import datetime
from datetime import datetime 
import matplotlib.collections as mcol
from matplotlib.legend_handler import HandlerLineCollection, HandlerTuple
from matplotlib.lines import Line2D


# Step 1: Read URLs from CSV
csv_file = 'web_pages.csv'  # Replace with your CSV file path
urls = pd.read_csv(csv_file)

# Function to scrape data
def scrape_data(urls):
    scraped_tables = {}

    # Iterate over rows in the CSV file
    for _, row in urls.iterrows():  
        url = row['URL']

        # Get the first column name from CSV file
        first_column_name = row['start_column_name']  
        try:
            response = requests.get(url)
            tables_list = pd.read_html(response.text)
            for table in tables_list:

                # Check if the first column of the table matches the desired name
                if table.columns[0] == first_column_name:
                    scraped_tables[url] = table
                    print(f"\nScraped table from: {url} \nfirst column: '{first_column_name} \nscrapped date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                    # Print the first few rows of the table
                    print(table.head())  
                    break
        except ValueError:
            print(f"No tables found in {url}")
        except Exception as e:
            print(f"Error occurred while scraping {url}: {e}")
    return scraped_tables

# Function to clean and convert data
def clean_and_convert_to_numeric(table, columns_to_convert):
    for column in columns_to_convert:
        if column in table:
            print(f"Converting {column} to numeric data")
            table[column] = table[column].str.replace('Â°', '')
            table[column] = pd.to_numeric(table[column], errors='coerce')
            print(table[column].head())
    return table

#Saving scraped data to HDF5 file
def save_to_hdf5(scraped_tables, hdf5_file, scrape_date):
    with pd.HDFStore(hdf5_file, 'a') as store:
        for url_counter, (url, table) in enumerate(scraped_tables.items(), start=1):

            # Ensure the table is a DataFrame before attempting to save
            if isinstance(table, pd.DataFrame):
                table_name = f"URL_{url_counter}_date_{scrape_date}"
                store.put(table_name, table)

                # Save URL and date as attributes
                store.get_storer(table_name).attrs.metadata = {'url': url, 'scrape_date': scrape_date}
            else:
                print(f"Skipped saving non-DataFrame data from {url}")
           
        
# Function to visualize data
def visualize_data(scraped_tables):
    for url, table in scraped_tables.items():
        print(f"Visualizing data from {url} with shape {table.shape}")
        if isinstance(table, pd.DataFrame) and not table.empty and len (table.columns) >= 2:
            try:
                # Checking if the third column is numeric for plotting
                if pd.api.types.is_numeric_dtype(table.iloc[:, 2]):
                    plt.figure()
                    #Using a bar plot as default
                    table.plot(kind='bar', x=table.columns[1], width=1.2)                    
                    
                    plt.title(f"Bar plot from {url}")
                    # Plot legend outside the plot area
                    plt.legend(bbox_to_anchor=(1.04, 0.5), loc="center left", borderaxespad=0)
                    plt.show()

                elif table.columns[2] in table.columns:
                    # Plot 2D line graph
                    plt.figure()
                    #Convert table values to numeric
                    table.iloc[:, 1:] = table.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')
                    for i in range(1, 4):
                        plt.plot(table.iloc[:, 0], table.iloc[:, i], label=table.columns[i])
                        plt.yticks(np.arange(0, 2500, 200))
                        
                        plt.xticks(rotation=90)
                        plt.title(f"2D line graph from {url}")
                        plt.legend()
                    plt.show()

                    
                else:
                    print(f"Skipped plotting from {url} because third column is not numeric")
            except Exception as e:
                print(f"Error occurred while plotting {url}: {e}")
        else:
            print(f"Skipped plotting from {url}")
               

# HDF5 file name
hdf5_file = 'scraped_data2.h5'
 
#scraping count
number_of_times = 1
for _ in range(number_of_times):
    scrape_date = datetime.now().strftime("%Y%m%d")
    scraped_data = scrape_data(urls)

    # Save to HDF5 and visualize after processing all URLs
    save_to_hdf5(scraped_data, hdf5_file, scrape_date)
    visualize_data(scraped_data)

